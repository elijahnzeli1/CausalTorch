{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CausalTorch: Image Generation with Causal Constraints\n",
    "\n",
    "This notebook demonstrates how to use CausalTorch to generate images that adhere to causal rules. We'll implement the classic example where \"If it rains, the ground is wet\" - our model will ensure that any generated image with rain also shows wet ground."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install CausalTorch if not already installed\n",
    "%pip install -e ..\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Training Data\n",
    "\n",
    "Let's create a simple dataset of synthetic images with rain and wet/dry ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_image(has_rain=True, img_size=28):\n",
    "    \"\"\"Generate a synthetic image with or without rain and appropriate ground wetness\"\"\"\n",
    "    img = np.zeros((img_size, img_size))\n",
    "    \n",
    "    if has_rain:\n",
    "        # Add rain (vertical lines)\n",
    "        rain_intensity = 0.8\n",
    "        for i in range(0, img_size, 3):\n",
    "            # Random raindrop length\n",
    "            drop_length = np.random.randint(5, 15)\n",
    "            start_y = np.random.randint(0, img_size - drop_length)\n",
    "            img[start_y:start_y+drop_length, i] = rain_intensity\n",
    "        \n",
    "        # Make ground wet (bottom 8 rows darker)\n",
    "        img[-8:, :] = 0.6\n",
    "    else:\n",
    "        # Dry ground is lighter\n",
    "        img[-8:, :] = 0.1\n",
    "    \n",
    "    # Add noise for realism\n",
    "    img += np.random.normal(0, 0.05, (img_size, img_size))\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Generate and display a few examples\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    has_rain = i < 3  # First row: rain, Second row: no rain\n",
    "    img = generate_synthetic_image(has_rain=has_rain)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"{'Rain' if has_rain else 'No Rain'}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the Causal Layer\n",
    "\n",
    "This is the core of our approach. The `CausalSymbolicLayer` enforces the relationship between rain and wet ground in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSymbolicLayer(nn.Module):\n",
    "    def __init__(self, causal_rules=None):\n",
    "        super().__init__()\n",
    "        # Default rule: rain → wet ground\n",
    "        self.causal_rules = causal_rules or {\n",
    "            \"rain\": {\"effect\": \"ground_wetness\", \"strength\": 0.9}\n",
    "        }\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"Apply causal constraints to latent vector z\n",
    "        z: [batch_size, latent_dim] where:\n",
    "           z[:, 0] = rain_intensity (0-1)\n",
    "           z[:, 1] = ground_wetness (0-1)\n",
    "        \"\"\"\n",
    "        # Get rain intensity and enforce causal relationship with ground wetness\n",
    "        rain_intensity = z[:, 0]\n",
    "        \n",
    "        # Simple causal rule: If rain_intensity > 0.5, ground must be wet\n",
    "        strength = self.causal_rules[\"rain\"][\"strength\"]\n",
    "        # Apply sigmoid to make a smooth transition around threshold 0.5\n",
    "        ground_wetness = torch.sigmoid((rain_intensity - 0.5) * 10) * strength \n",
    "        \n",
    "        # Override the ground_wetness value in the latent vector\n",
    "        z[:, 1] = ground_wetness\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the CNSG-Net Model (Causal VAE)\n",
    "\n",
    "We'll create a simple VAE with our causal layer integrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalVAE(pl.LightningModule):\n",
    "    def __init__(self, latent_dim=3, img_size=28):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Encoder (Image → Latent)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(img_size * img_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Mean and variance layers for VAE\n",
    "        self.fc_mu = nn.Linear(128, latent_dim)\n",
    "        self.fc_var = nn.Linear(128, latent_dim)\n",
    "        \n",
    "        # Causal layer to enforce rain → wet ground\n",
    "        self.causal_layer = CausalSymbolicLayer()\n",
    "        \n",
    "        # Decoder (Latent → Image)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, img_size * img_size),\n",
    "            nn.Sigmoid()  # Output pixel values 0-1\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        log_var = self.fc_var(h)\n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        # Apply causal constraints\n",
    "        z = self.causal_layer(z)\n",
    "        h = self.decoder(z)\n",
    "        return h.view(h.size(0), 1, self.img_size, self.img_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconstructed = self.decode(z)\n",
    "        return x_reconstructed, mu, log_var\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, has_rain = batch\n",
    "        x_reconstructed, mu, log_var = self(x)\n",
    "        \n",
    "        # Reconstruction loss\n",
    "        recon_loss = F.mse_loss(x_reconstructed, x)\n",
    "        \n",
    "        # KL Divergence\n",
    "        kl_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Causal loss - analyze generated images to check ground wetness\n",
    "        ground_region = x_reconstructed[:, :, -8:, :].mean(dim=(1, 2, 3))\n",
    "        \n",
    "        # For images with rain, ground should be wet (darker)\n",
    "        # For images without rain, no constraint\n",
    "        rain_indices = torch.where(has_rain == 1)[0]\n",
    "        causal_loss = 0\n",
    "        if len(rain_indices) > 0:\n",
    "            # Higher ground_region value means lower wetness (brighter pixels)\n",
    "            # We want wetness for rainy images, so ground_region should be lower\n",
    "            causal_loss = F.relu(ground_region[rain_indices] - 0.3).mean()\n",
    "        \n",
    "        # Total loss\n",
    "        loss = recon_loss + 0.1 * kl_loss + 5.0 * causal_loss\n",
    "        \n",
    "        self.log_dict({\n",
    "            'train_loss': loss,\n",
    "            'recon_loss': recon_loss,\n",
    "            'kl_loss': kl_loss,\n",
    "            'causal_loss': causal_loss\n",
    "        })\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    def generate(self, rain_intensity=1.0, num_samples=1):\n",
    "        \"\"\"Generate images with specified rain intensity\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Create a latent vector with the desired rain intensity\n",
    "            z = torch.randn(num_samples, self.latent_dim)  # Random latent vector\n",
    "            z[:, 0] = rain_intensity  # Set first dimension to rain intensity\n",
    "            \n",
    "            # Apply causal constraints and decode\n",
    "            images = self.decode(z)\n",
    "            return images\n",
    "\n",
    "# Create the model\n",
    "model = CausalVAE(latent_dim=3, img_size=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticRainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, num_samples=100, img_size=28):\n",
    "        self.num_samples = num_samples\n",
    "        self.img_size = img_size\n",
    "        self.data = []\n",
    "        self.labels = []  # 1 for rain, 0 for no rain\n",
    "        \n",
    "        # Generate data\n",
    "        for i in range(num_samples):\n",
    "            has_rain = (i < num_samples / 2)  # Half rain, half no rain\n",
    "            img = generate_synthetic_image(has_rain=has_rain, img_size=img_size)\n",
    "            self.data.append(torch.tensor(img, dtype=torch.float32).unsqueeze(0))\n",
    "            self.labels.append(1 if has_rain else 0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = SyntheticRainDataset(num_samples=100)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = pl.Trainer(max_epochs=30)\n",
    "\n",
    "# For demonstration purposes, let's only run a few steps\n",
    "# Remove this limit for full training\n",
    "print(\"Training for a few iterations...\")\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Images with Causal Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_generations(rain_intensities):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i, rain_intensity in enumerate(rain_intensities):\n",
    "        # Generate image with specified rain intensity\n",
    "        image = model.generate(rain_intensity=rain_intensity)\n",
    "        \n",
    "        # Get ground wetness from the image (average of bottom rows)\n",
    "        ground_wetness = 1.0 - image[0, 0, -8:, :].mean().item()  # Invert: darker = wetter\n",
    "        \n",
    "        # Display\n",
    "        plt.subplot(1, len(rain_intensities), i+1)\n",
    "        plt.imshow(image[0, 0].cpu().numpy(), cmap='gray')\n",
    "        plt.title(f\"Rain: {rain_intensity:.1f}\\nGround Wetness: {ground_wetness:.2f}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate images with varying rain intensities\n",
    "rain_intensities = [0.0, 0.3, 0.5, 0.7, 1.0]\n",
    "display_generations(rain_intensities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Causal Fidelity Score (CFS)\n",
    "\n",
    "Let's compute how well our model adheres to the causal rule \"rain → wet ground\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cfs():\n",
    "    \"\"\"Calculate Causal Fidelity Score\"\"\"\n",
    "    # Generate 50 images across a range of rain intensities\n",
    "    rain_intensities = np.linspace(0, 1, 50)\n",
    "    correct = 0\n",
    "    \n",
    "    for rain in rain_intensities:\n",
    "        image = model.generate(rain_intensity=rain)\n",
    "        \n",
    "        # Calculate ground wetness\n",
    "        ground_wetness = 1.0 - image[0, 0, -8:, :].mean().item()  # Invert: darker = wetter\n",
    "        \n",
    "        # Check if the causal rule is satisfied\n",
    "        # Rule: If rain_intensity > 0.5, ground_wetness should be > 0.5\n",
    "        if (rain > 0.5 and ground_wetness > 0.5) or (rain <= 0.5 and ground_wetness <= 0.7):\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / len(rain_intensities)\n",
    "\n",
    "# Calculate CFS\n",
    "cfs = calculate_cfs()\n",
    "print(f\"Causal Fidelity Score (CFS): {cfs:.2f} (higher is better)\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(['CFS'], [cfs], color='blue')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Causal Fidelity Score')\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label='Minimum Acceptable')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Latent Space Traversal\n",
    "\n",
    "Let's explore the latent space to see how our causal constraints affect generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_traversal():\n",
    "    # Create a grid of images by varying two dimensions of the latent space\n",
    "    dim1_values = np.linspace(0, 1, 5)  # rain intensity\n",
    "    dim2_values = np.linspace(-1, 1, 4)  # time of day (arbitrary)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    for i, dim2 in enumerate(dim2_values):\n",
    "        for j, dim1 in enumerate(dim1_values):\n",
    "            # Create latent vector\n",
    "            z = torch.zeros(1, 3)  # 3-dimensional latent space\n",
    "            z[0, 0] = dim1  # rain intensity\n",
    "            z[0, 2] = dim2  # time of day\n",
    "            \n",
    "            # Ground wetness (dimension 1) will be enforced by the causal layer\n",
    "            \n",
    "            # Generate image\n",
    "            with torch.no_grad():\n",
    "                # Apply causal constraints\n",
    "                z_causal = model.causal_layer(z)\n",
    "                image = model.decode(z)\n",
    "            \n",
    "            # Get ground wetness from the causal z\n",
    "            ground_wetness = z_causal[0, 1].item()\n",
    "            \n",
    "            # Display\n",
    "            ax = plt.subplot(len(dim2_values), len(dim1_values), i*len(dim1_values) + j + 1)\n",
    "            plt.imshow(image[0, 0].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f\"Rain: {dim1:.1f}, GW: {ground_wetness:.2f}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Latent Space Traversal\\nRows: Time of Day, Columns: Rain Intensity\", fontsize=16)\n",
    "    plt.tight_layout(pad=1.5)\n",
    "    plt.show()\n",
    "\n",
    "# Show latent space traversal\n",
    "latent_traversal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Counterfactual Analysis\n",
    "\n",
    "Let's perform a simple counterfactual intervention in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counterfactual_analysis():\n",
    "    # Take a random data point\n",
    "    img, has_rain = dataset[10]\n",
    "    \n",
    "    # Encode it\n",
    "    with torch.no_grad():\n",
    "        mu, log_var = model.encode(img.unsqueeze(0))\n",
    "        z = model.reparameterize(mu, log_var)\n",
    "        \n",
    "        # Original image\n",
    "        original_img = model.decode(z)\n",
    "        \n",
    "        # Counterfactual: What if it was raining/not raining?\n",
    "        z_cf = z.clone()\n",
    "        z_cf[0, 0] = 1.0 if z[0, 0] < 0.5 else 0.0  # Flip rain intensity\n",
    "        \n",
    "        # The causal layer will automatically update ground wetness\n",
    "        cf_img = model.decode(z_cf)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original_img[0, 0].cpu().numpy(), cmap='gray')\n",
    "    plt.title(f\"Original (Rain: {z[0, 0].item():.2f})\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cf_img[0, 0].cpu().numpy(), cmap='gray')\n",
    "    plt.title(f\"Counterfactual (Rain: {z_cf[0, 0].item():.2f})\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Counterfactual Analysis: What if it was (not) raining?\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Perform counterfactual analysis\n",
    "counterfactual_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how CausalTorch can be used to generate images that adhere to causal constraints. Key takeaways:\n",
    "\n",
    "1. We enforced the causal rule \"rain → wet ground\" using a specialized layer in the latent space\n",
    "2. The model was trained with minimal data (just 100 synthetic examples)\n",
    "3. We validated the model's adherence to causal rules using the Causal Fidelity Score (CFS)\n",
    "4. We demonstrated counterfactual reasoning by manipulating the causal variables\n",
    "\n",
    "This approach ensures that generated images respect real-world physics and logical consistency. The same principles can be applied to more complex domains like medical imaging or scientific visualizations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
