{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d258097",
   "metadata": {},
   "source": [
    "# CausalTorch: Text Generation with Causal Constraints\n",
    "\n",
    "This notebook demonstrates how to use the CausalTorch library to generate text with causal constraints. The CNSG-Net model combines a neural language model with symbolic causal rules to ensure logical consistency in the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bda59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "from causaltorch import CNSG_Net\n",
    "from causaltorch.rules import CausalRuleEngine\n",
    "from causaltorch.utils import calculate_rule_violation_rate\n",
    "\n",
    "# Check for CUDA availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43586cd",
   "metadata": {},
   "source": [
    "## 1. Create Causal Rules\n",
    "\n",
    "First, we'll define some physical causal rules for our text generation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for our rules if it doesn't exist\n",
    "os.makedirs(\"rules\", exist_ok=True)\n",
    "\n",
    "# Define some simple physical causal rules\n",
    "physical_rules = [\n",
    "    {\n",
    "        \"name\": \"rain_wet_ground\",\n",
    "        \"description\": \"If it rains, the ground gets wet\",\n",
    "        \"pattern\": \"rain|raining|rainy|downpour\",\n",
    "        \"consequences\": [\n",
    "            {\n",
    "                \"text\": \"wet\",\n",
    "                \"intensity\": 5.0,\n",
    "                \"required\": True\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"puddle\",\n",
    "                \"intensity\": 3.0,\n",
    "                \"required\": False\n",
    "            }\n",
    "        ],\n",
    "        \"type\": \"physical\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"fire_heat\",\n",
    "        \"description\": \"Fire produces heat\",\n",
    "        \"pattern\": \"fire|flame|burning\",\n",
    "        \"consequences\": [\n",
    "            {\n",
    "                \"text\": \"heat\",\n",
    "                \"intensity\": 4.0,\n",
    "                \"required\": True\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"warm\",\n",
    "                \"intensity\": 3.0,\n",
    "                \"required\": False\n",
    "            }\n",
    "        ],\n",
    "        \"type\": \"physical\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Save rules to file\n",
    "rules_file = \"rules/physical_rules.json\"\n",
    "with open(rules_file, \"w\") as f:\n",
    "    json.dump(physical_rules, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(physical_rules)} rules to {rules_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d23e36",
   "metadata": {},
   "source": [
    "## 2. Initialize the CNSG-Net Model\n",
    "\n",
    "Now we'll initialize the Causal Neural-Symbolic Generative Network with the rules we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae180788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with our physical rules\n",
    "model = CNSG_Net(\n",
    "    base_model_name=\"gpt2\",  # We'll use GPT-2 small as the base model\n",
    "    rules_file=rules_file\n",
    ")\n",
    "\n",
    "# Move to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721478d6",
   "metadata": {},
   "source": [
    "## 3. Generate Text with Causal Constraints\n",
    "\n",
    "Let's test our model by generating text that should follow our defined causal rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd13e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"It started raining heavily. The ground\",\n",
    "    \"The fire was burning brightly in the fireplace. I could feel the\",\n",
    "    \"Despite the heavy rain, the ground remained\",  # This should be interesting - will it respect causality?\n",
    "    \"The match struck the surface and a fire started. The room began to feel\"\n",
    "]\n",
    "\n",
    "generated_texts = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    output = model.generate(\n",
    "        prompt, \n",
    "        max_length=100,\n",
    "        do_sample=True,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    print(f\"Generated: {output}\")\n",
    "    generated_texts.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6528a3c",
   "metadata": {},
   "source": [
    "## 4. Evaluate Causal Consistency\n",
    "\n",
    "Now let's evaluate how well our model respects the causal constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate violation rate\n",
    "violation_stats = calculate_rule_violation_rate(\n",
    "    model.rule_engine,\n",
    "    generated_texts,\n",
    "    prompts\n",
    ")\n",
    "\n",
    "print(f\"Violation rate: {violation_stats['violation_rate'] * 100:.2f}%\")\n",
    "if violation_stats['violations_by_rule']:\n",
    "    print(\"Violations by rule:\")\n",
    "    for rule, count in violation_stats['violations_by_rule'].items():\n",
    "        print(f\"  - {rule}: {count}\")\n",
    "else:\n",
    "    print(\"No violations detected! All causal rules were respected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7c7623",
   "metadata": {},
   "source": [
    "## 5. Compare with Baseline (No Causal Rules)\n",
    "\n",
    "For comparison, let's see how a standard language model (without causal constraints) generates text for the same prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load standard GPT-2 model without causal constraints\n",
    "baseline_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "baseline_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "\n",
    "baseline_generated = []\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    input_ids = baseline_tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Generate text\n",
    "    output_ids = baseline_model.generate(\n",
    "        input_ids,\n",
    "        max_length=100,\n",
    "        do_sample=True,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    output = baseline_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    print(f\"Baseline Generated: {output}\")\n",
    "    baseline_generated.append(output)\n",
    "\n",
    "# Calculate violation rate for baseline model\n",
    "baseline_violation_stats = calculate_rule_violation_rate(\n",
    "    model.rule_engine,  # Use the same rule engine to evaluate\n",
    "    baseline_generated,\n",
    "    prompts\n",
    ")\n",
    "\n",
    "print(f\"\\nBaseline violation rate: {baseline_violation_stats['violation_rate'] * 100:.2f}%\")\n",
    "if baseline_violation_stats['violations_by_rule']:\n",
    "    print(\"Violations by rule:\")\n",
    "    for rule, count in baseline_violation_stats['violations_by_rule'].items():\n",
    "        print(f\"  - {rule}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274e6ff",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "We've seen how the CNSG-Net model can generate text with improved causal consistency compared to a standard language model. By encoding causal rules, we ensure that generated text follows logical patterns like \"rain causes wet ground\" and \"fire produces heat\".\n",
    "\n",
    "This approach allows for more reliable and trustworthy text generation, especially for domains where logical consistency is critical."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
